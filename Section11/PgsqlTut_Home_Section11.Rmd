---
title: "PostgreSQL Tutorial - Home - Section 11"
output: 
  html_notebook:
    theme: sandstone
    highlight: zenburn
    toc: true
    toc_float: true
---

Load libraries.
```{r}
library(DBI)
library(odbc)
library(RPostgres)
library(dplyr)
# library(rlang)
```

Helper function for simplifying database disconnection/removal.

```{r}
my_dbDisconnect <- function(x) {
  x_expr <- rlang::enexpr(x)
  if (exists(rlang::as_string(x_expr))) { dbDisconnect(x); rm(x); }
}
```


# Managing Tables

## Data Types

### Boolean

Keyword(s): `BOOLEAN` or `BOOL`

| Values  | Notes |
|---------|------------------------------------------------|
| `FALSE` | `0`, `'no'`, `'n'`, `'f'`, `'false'` all equal `FALSE` |
| `TRUE`  | `1`, `'yes'`, `'y'`, `'t'`, `'true'` all equal `TRUE`  |
| `NULL`  |       |


### Character

There are three types of character fields: `CHAR`, `VARCHAR`, and `TEXT`.

| Data Type | Keyword(s) | Notes | 
|-----------|--------------|----------------------------------------|
| Character | `CHAR(n)`  | `n` is how many characters per entry; fixed-length character values with space padding to fill in `n` |
| Varying Character | `VARCHAR(n)` | variable length; `n` is max number of characters per entry; unlike, `CHAR` the entries are not padded with spaces |
| Text      | `TEXT`     | variable length; theoretically unlimited length |


### Numeric

PostgreSQL provides 2 types of numbers:

1. Integers
2. Floating-Point Numbers

#### Integer

PostgreSQL provies 4 main types of integers: `SMALLINT`, `INTEGER`, `BIGINT` and `SERIAL`.

There are many different types of integers. Read the documentation (Chapter 8, Data Types) for the full list.

| Data Type | Keyword(s) | Notes |
|-----------|------------|----------------------------------------|
| Small Integer | `SMALLINT` or `INT2` | 2-byte signed integer:<br /> -32,768 to 32,767 |
| Integer       | `INTEGER` or `INT`   | 4-byte signed integer:<br /> -2,147,483,648 to 2,147,483,647 |
| Big Integer   | `BIGINT` or `INT8`   | 8-byte signed integer:<br />  -9,223,372,036,854,775,808 to 9,223,372,036,854,775,807 |
| Serial        | `SERIAL`             | autoincrementing 4-byte integer |

#### Floating-Point Number

There are 2 main types of floating-point numbers: `NUMERIC`, `REAL`/`DOUBLE PRECISION`, and `FLOAT`.

| Data Type | Keyword(s) | Notes |
|-----------|------------|-----------------------------------------|
| Exact Arbitrary Precision Number  | `NUMERIC(p, s)` | `p` is precision, `s` is scale; precision is total count of signif. digits in the number as a whole, scale is count of digits after the decimal point; 23.5141 is a `NUMERIC(6, 4)`; recommended for storing monetary amounts and other quantities where exactness is required |
| Inexact Variable Precision Number | `REAL` | typically, has a range of at least 1E-37 to 1E+37 with a precision of at least 6 decimal digits |
| Inexact Variable Precision Number | `DOUBLE PRECISION` | typically has a range of around 1E-307 to 1E+308 with a precision of at least 15 digits |
| SQL standard `FLOAT` | `FLOAT(n)` | `FLOAT(1)` to `FLOAT(24)` is just `REAL`; `FLOAT(25)` to `FLOAT(53)` is just `DOUBLE PRECISION` |

### Temporal Data Types

PostgreSQL has 5 main temporal data types: `DATE`, `TIME`, `TIMESTAMP`, `TIMESTAMPTZ`, and `INTERVAL`.

| Data Type | Keyword(s) | Notes |
|-----------|------------|-------------------------------------------|
| Date | `DATE` | calendar date (year, month, day) |
| Time | `TIME` | time of day (no time zone), HH:MM:SS from `00:00:00` to `24:00:00` |
| Time w/ timezone | `TIMETZ` | time of day (w/ time zone), HH:MM:SS from `00:00:00` to `24:00:00` |
| Datetime | `TIMESTAMP` | e.g., `2016-06-22 19:10:25` |
| Datetime w/ timezone | `TIMESTAMPTZ` | e.g., `2016-06-22 19:10:25-07` |
| Interval | `INTERVAL` | There's quite a bit to this... read documentation section 8.5.4. Interval Input for more info |


### Arrays

In PostgreSQL, you can store an array of strings, an array of integers, etc., in array columns. The array comes in handy in some situations e.g., storing days of the week, months of the year.


### JSON

PostgreSQL provides two JSON data types: `JSON` and `JSONB` for storing JSON data.

The `JSON` data type stores plain JSON data that requires reparsing for each processing, while `JSONB` data type stores JSON data in a binary format which is faster to process but slower to insert. In addition, `JSONB` supports indexing, which can be an advantage.


### UUID

The `UUID` data type allows you to store Universal Unique Identifiers defined by RFC 4122 . The `UUID` values guarantee a better uniqueness than `SERIAL` and can be used to hide sensitive data exposed to the public such as values of `id` in URL.


### Special Data Types

Besides the primitive data types, PostgreSQL also provides several special data types related to geometric and network.

* `box` - a rectangular box
* `line` - a set of points
* `point` - a geometric pair of numbers
* `lseg` - a line segment
* `polygon` - a closed geometric
* `inet` - an IP4 address
* `macaddr` -  a MAC address


## CREATE TABLE

Here's the general `CREATE TABLE` syntax.

```
CREATE TABLE table_name (
  column_name  TYPE  column_constraint,
  column_name  TYPE  column_constraint,
  ...
  table_constraint  table_constraint ...
) INHERITS existing_table_name;
```

### Column constraints

Here are some commonly used column constraints.

* `NOT NULL` - A record's value in such a column cannot be `NULL`.
* `UNIQUE` - A record's value in such a column must be unique _across the whole table_. However, the column can have many `NULL` values because PostgreSQL considers each `NULL` value unique.
* `PRIMARY KEY` - This is a combination of `NOT NULL` and `UNIQUE`. This can be used as a column constraint if only one column is the primary key. If multiple columns are the primary key, you'll have to define those primary keys as table constraints.
* `CHECK (condition)` - Enables a `CHECK` condition when you insert or update data.
* `REFERENCES` - Constrains a record's value in such a column to a corresponding value in another table's column. It's used to define the foreign key constraint.

### Table constraints

Here are some common table constraints.

* `UNIQUE (column_name, column_name, ...)` - Force value stored in the columns listed to be unique.
* `PRIMARY KEY (column_name, column_name, ...)` - Define a primary key consisting of multiple columns.
* `CHECK (condition)` - Like column constraing `CHECK`.
* `REFERENCES` - Like column constraint `REFERENCES`.

### CREATE TABEL example

We'll create tables named "account", "role", and "account_roles".

Connect to the _**example**_ database.

```{r}
con_ex <- dbConnect(odbc::odbc(), "PostgreSQL AWS example")
```

```{sql connection=con_ex}
DROP TABLE IF EXISTS account_role;
DROP TABLE IF EXISTS account;
DROP TABLE IF EXISTS role;
```

Create the "account" table.

```{sql connection=con_ex}
CREATE TABLE IF NOT EXISTS account (
  user_id     SERIAL        PRIMARY KEY,
  username    VARCHAR(50)   UNIQUE NOT NULL,
  password    VARCHAR(50)   NOT NULL,
  email       VARCHAR(355)  UNIQUE NOT NULL,
  created_on  TIMESTAMP     NOT NULL DEFAULT CURRENT_TIMESTAMP,
  last_login  TIMESTAMP
);
```

Create the "role" table.

```{sql connection=con_ex}
CREATE TABLE IF NOT EXISTS role (
  role_id    SERIAL        PRIMARY KEY,
  role_name  VARCHAR(255)  UNIQUE NOT NULL
)
```

Create the "account_role" table.

```{sql connection=con_ex}
CREATE TABLE IF NOT EXISTS account_role (
  user_id     INTEGER    NOT NULL,
  role_id     INTEGER    NOT NULL,
  grant_date  TIMESTAMP  WITHOUT TIME ZONE DEFAULT CURRENT_TIMESTAMP,
  PRIMARY KEY (user_id, role_id),            -- table constraint #1
  CONSTRAINT account_role_role_id_fkey FOREIGN KEY (role_id)
    REFERENCES role (role_id) MATCH SIMPLE
    ON UPDATE NO ACTION ON DELETE NO ACTION, -- table constraint #2
  CONSTRAINT account_role_user_id_fkey FOREIGN KEY (user_id)
    REFERENCES account (user_id) MATCH SIMPLE
    ON UPDATE NO ACTION ON DELETE NO ACTION  -- table constraint #3
);
```

The `PRIMARY KEY` table constraint makes sense.

The 2nd and 3rd constraints except `MATCH SIMPLE`. I'm guessing what this means, but I'll have to wait until there's more info on table constraints language. Looking forward to that!

Before I move on, I'd like to add some data to these tables to make sure I understand how these work. The "account_role" looks like a junction table to make a many-to-many relationship possible between accounts and roles.

```{sql connection=con_ex}
INSERT INTO 
  account(username, password, email)
VALUES
  ('bill100', 'samwise', 'bill100@gmail.com'), -- admin, power_user
  ('jenny', 'gamgee', 'jenny@gmail.com'),      -- admin, user
  ('luke1234', 'frodo', 'tolkienisawesome@gmail.com'), -- user
  ('samantha2000', 'baggins', 'billy.the.kid@hotmail.com'); -- power_user
```

```{sql connection=con_ex}
SELECT * FROM account;
```

```{sql connection=con_ex}
INSERT INTO
  role(role_name)
VALUES
  ('user'),
  ('power_user'),
  ('admin');
```

```{sql connection=con_ex}
SELECT * FROM role;
```

```{sql connection=con_ex}
INSERT INTO
  account_role(user_id, role_id)
VALUES
  (1, 1),
  (1, 3),
  (2, 2),
  (2, 3),
  (3, 1),
  (4, 2);
```

```{sql connection=con_ex}
SELECT * FROM account_role;
```

What roles does the user "bill100" have?

This requires a double join across the junction table "account_role".

```{sql connection=con_ex}
SELECT
  account_role.user_id,
  account_role.role_id,
  -- role.role_id,
  role.role_name
FROM
  account_role
INNER JOIN
  role
  ON account_role.role_id = role.role_id;
```

```{sql connection=con_ex}
SELECT
  account.user_id,
  account.username,
  account_role_role.role_id,
  account_role_role.role_name
FROM
  account
INNER JOIN
  (
    SELECT
      account_role.user_id,
      account_role.role_id,
      role.role_name
    FROM
      account_role
    INNER JOIN
      role
    ON account_role.role_id = role.role_id
  ) AS account_role_role
  ON account.user_id = account_role_role.user_id
  WHERE account.username = 'bill100';
```

```{r}
dbGetQuery(con_ex,
"
SELECT
  -- account.user_id,
  -- account.username,
  -- account_role_role.role_id,
  account_role_role.role_name
FROM
  account
INNER JOIN
  (
    SELECT
      account_role.user_id,
      account_role.role_id,
      role.role_name
    FROM
      account_role
    INNER JOIN
      role
    ON account_role.role_id = role.role_id
  ) AS account_role_role
  ON account.user_id = account_role_role.user_id
  WHERE account.username = 'bill100';
") %>% 
  dplyr::pull()
```

Disconnect from the _**example**_ database.

```{r}
my_dbDisconnect(con_ex)
```


## SELECT INTO

`SELECT INTO` allows you to create a new table and insert the data from a query. `SELECT INTO` doesn't return data to the client.

Here's the syntax.

```
SELECT
  col_1, col_2, ...
INTO [TEMPORARY] [TABLE]
  new_table
FROM
  existing_table
WHERE
  [condition];
```

You can also do joins.

```
SELECT
  existing_table_1.col_1, 
  existing_table_1.col_2,
  ...,
  existing_table_2.col_1,
  existing_table_2.col_2,
  ...
INTO [TEMPORARY] [TABLE]
  new_table
FROM
  existing_table_1
INNER JOIN
  existing_table_2
  ON existing_table_1.col_1 = existing_table_2.col_1;
```

Note that you cannot use the `SELECT INTO` statement in PL/pgSQL or ECPG because they interpret the `INTO`clause differently. Use the `CREATE TABLE AS` statement instead... it provides more functionality.

We'll use the "film" table in the _**dvdrental**_ database.

```{r}
con_dvd <- dbConnect(odbc::odbc(), "PostgreSQL AWS dvdrental")
```

Let's create a temporary table of all the films whose ratings are 'R' and the rental period is 5 days.

```{sql connection=con_dvd}
DROP TABLE IF EXISTS film_r;
```


```{sql connection=con_dvd}
SELECT
  film_id,
  title,
  rating
INTO TEMPORARY TABLE
  film_r
FROM
  film
WHERE
  rating = 'R' AND rental_duration = 5
ORDER BY
  title;
```

The temporary table created above doesn't show up in the list of tables returned by `DBI::dbListTables`.

```{r}
dbListTables(con_dvd)
```

But it is there now.

```{sql connection=con_dvd}
SELECT * FROM film_r;
```

>
> What happens when I disconnect and reconnect?
> 
```{r}
# dbDisconnect(con_dvd)
# con_dvd <- dbConnect(odbc::odbc(), "PostgreSQL AWS dvdrental")
```

```{sql connection=con_dvd}
-- SELECT * FROM film_r;
```
> 
> It disappears!
> 

How about a temporary table of short films (i.e., `length` < 60 minutes)?

```{sql connection=con_dvd}
DROP TABLE IF EXISTS short_film;
```


```{sql connection=con_dvd}
SELECT
  film_id,
  title,
  length
INTO TEMPORARY TABLE
  short_film
FROM
  film
WHERE
  length < 60
ORDER BY
  length DESC,
  title;
```

```{sql connection=con_dvd}
SELECT * FROM short_film;
```

Cool.

Disconnect from the _**dvdrental**_ database.

```{r}
my_dbDisconnect(con_dvd)
```

## CREATE TABLE AS

The `CREATE TABLE ... AS` statement is like `SELECT INTO` in that you create a new table from what's returned by a query. `CREATE TABLE AS` is preferred though because it can be used in PL/pgSQL and provides more functionality.

Here's the syntax.

```
CREATE [TEMPORARY] TABLE 
  table_name
AS
  {query};
```

If you want to rename the columns returned by the query, you can list them after the table name.

```
CREATE TABLE
  table_name(col_1, col_2, ...)
AS
  {query};
```

You can also use the `IF NOT EXISTS` keywords to avoid errors if the table already exists.

```
CREATE TABLE IF NOT EXISTS
  table_name
AS
  {query};
```

We'll use the "film" and "film_category" tables from the _**dvdrental**_ database.

```{r}
con_dvd <- dbConnect(odbc::odbc(), "PostgreSQL AWS dvdrental")
```

Heres the query that we'll use to generate a new table.

```{sql connection=con_dvd}
SELECT
  film_id,
  title,
  release_year,
  length,
  rating
FROM
  film
INNER JOIN
  film_category USING (film_id)
WHERE
  category_id = 1; -- 1 is the category ID for action films
```

Now let's just use the query above to create a new temporary table.

```{sql connection=con_dvd}
DROP TABLE IF EXISTS action_film;
```


```{sql connection=con_dvd}
CREATE TABLE IF NOT EXISTS
  action_film
AS
  SELECT
    film_id,
    title,
    release_year,
    length,
    rating
  FROM
    film
  INNER JOIN
    film_category USING (film_id)
  WHERE
    category_id = 1;
```

```{sql connection=con_dvd}
SELECT * FROM action_film ORDER BY length DESC;
```

To check the structure of the action_film, you can use the following command in the psql tool:

```	
ssh -i ~/Box\ Sync/Keys/ubuntu_18_04_postgresql.pem ubuntu@ec2-3-83-161-243.compute-1.amazonaws.com
psql -U postgres
\c dvdrental
\d action_film
\q
exit
```

If the `SELECT` clause contains expressions, it's best to override the column names by listing them explicitly.

```{sql connection=con_dvd}
SELECT
  rating,
  COUNT(film_id)
FROM
  film
GROUP BY
  rating;
```

```{sql connection=con_dvd}
DROP TABLE IF EXISTS film_rating;
```

```{sql connection=con_dvd}
CREATE TABLE IF NOT EXISTS
  film_rating (rating, film_count)
AS
  SELECT
    rating,
    COUNT(film_id)
  FROM
    film
  GROUP BY
    rating;
```

```{sql connection=con_dvd}
SELECT * FROM film_rating ORDER BY film_count DESC;
```

```
ssh -i ~/Box\ Sync/Keys/ubuntu_18_04_postgresql.pem ubuntu@ec2-3-83-161-243.compute-1.amazonaws.com
psql -U postgres
\c dvdrental
\d film_rating
\q
exit
```

Disconnect from the _**dvdrental**_ database.

```{r}
my_dbDisconnect(con_dvd)
```


## SERIAL To Create Auto-increment Column

In PostgreSQL, a sequence is a special kind of database object that generates a sequence of integers. When creating a new table, the sequence is created through the SERIAL pseudo-type.

Here's the syntax.

```
CREATE TABLE table_name(
  id  SERIAL  [column_constraints]
);
```

By assigning the SERIAL pseudo-type to the `id` column, PostgreSQL will perform the following:

* Creates a sequence object and set the next value generated by the sequence as the default value for the column.
* Adds the `NOT NULL` constraint to the column because a sequence always generates an integer, which is a non-null value.
* Assigns the owner of the sequence to the `id` column; as a result, the sequence object is deleted when the `id` column or table is dropped.

This statement...

```
CREATE TABLE table_name(
  id SERIAL
);
```

... is equivalent to...

```
CREATE SEQUENCE table_name_id_seq;

CREATE TABLE table_name(
 id  INTEGER  NOT NULL DEFAULT nextval('table_name_id_seq')
);

ALTER SEQUENCE
  table_name_id_seq
OWNED BY
  table_name.id;
```

PostgreSQL has three SERIAL pseudotypes: `SMALLSERIAL`, `SERIAL`, and `BIGSERIAL`.

| Name | Storage Size | Range |
|------|--------------|----------------------|
| `SMALLSERIAL` | 2 bytes | 1 to 32,767 |
| `SERIAL` | 4 bytes | 1 to 2,147,483,647 |
| `BIGSERIAL` | 8 bytes | 1 to 922,337,2036,854,775,807 |

`SERIAL` does not implicitly create an index on the column or make the column as a primary key column. However, this can easily be done by specifying the `PRIMARY KEY` constraint on the column.

Let's use the _**example**_ database.

```{r}
con_ex <- dbConnect(odbc::odbc(), "PostgreSQL AWS example")
```

```{sql connection=con_ex}
DROP TABLE IF EXISTS fruits;
```

```{sql connection=con_ex}
CREATE TABLE fruits(
  id    SERIAL   PRIMARY KEY,
  name  VARCHAR  NOT NULL
);
```

To insert values, you can just insert into the non-serial columns.

```{sql connection=con_ex}
INSERT INTO
  fruits(name)
VALUES
  ('orange');
```

```{sql connection=con_ex}
SELECT * FROM fruits;
```

Or you can use the `DEFAULT` keyword in the serial column.

```{sql connection=con_ex}
INSERT INTO
  fruits(id, name)
VALUES
  (DEFAULT, 'apple');
```

```{sql connection=con_ex}
SELECT * FROM fruits;
```

```{sql connection=con_ex}
SELECT * FROM pg_get_serial_sequence('fruits','id');
```

```{sql connection=con_ex}
SELECT currval(pg_get_serial_sequence('fruits', 'id'));
```

If you want to get the value generated in a sequence when you insert a new row, use a `RETURNING` clause identifying the sequence/serial colmuns in the `INSERT` statement.

```{sql connection=con_ex}
INSERT INTO
  fruits(name)
VALUES
  ('banana')
RETURNING
  id;
```

```{sql connection=con_ex}
SELECT * FROM fruits;
```

**NOTE**: The sequence generator operation is not transaction-safe. It means that if two concurrent database connections attempt to get the next value from a sequence, each client will get a different value. If one of the clients rolls back the transaction, the sequence number of that client will be unused, creating a gap in the sequence.

Disconnect from the _**example**_ database.

```{r}
my_dbDisconnect(con_ex)
```


## ALTER TABLE

To change existing table structure, use the `ALTER TABLE` statement.

Here's the syntax.

```
ALTER TABLE 
  table_name 
  {action};
```

`ALTER TABLE` helps you:

* Add a column

`ALTER TABLE table_name ADD COLUMN new_column_name {TYPE};`

* Drop a column

`ALTER TABLE table_name DROP COLUMN column_to_drop;`

* Rename a column

`ALTER TABE table_name RENAME COLUMN column_name TO new_column_name;`

* Change a column's data type

`ALTER TABLE table_name ALTER COLUMN column_name SET DATA TYPE {TYPE};`

* Set a default value for a column, or drop the default value

`ALTER TABLE table_name ALTER COLUMN column_name SET DEFAULT {value};`

`ALTER TABLE table_name ALTER COLUMN column_name DROP DEFAULT;`

* Add or drop(?) a `CHECK` constraint to a column

`ALTER TABLE table_name ADD CHECK {expression};`

`ALTER TABLE table_name DROP CHECK;` (???)

* Add or drop a `NOT NULL` constraint

`ALTER TABLE table_name ALTER COLUMN column_name SET NOT NULL;`

`ALTER TABLE table_name ALTER COLUMN column_name DROP NOT NULL;`

* Add a constraint

`ALTER TABLE table_name ADD CONSTRAINT constraint_name constraint_definition;`

* Rename a table

`ALTER TABLE table_name RENAME TO new_table_name;`

We'll create a new table "link" in the _**example**_ database.

```{r}
con_ex <- dbConnect(odbc::odbc(), "PostgreSQL AWS example")
```

```{sql connection=con_ex}
DROP TABLE IF EXISTS link_at;
```

```{sql connection=con_ex}
CREATE TABLE link_at(
  link_id  SERIAL        PRIMARY KEY,
  title    VARCHAR(512)  NOT NULL,
  url      VARCHAR(1024) NOT NULL UNIQUE
)
```

Add a new column `active`.

```{sql connection=con_ex}
ALTER TABLE 
  link_at 
ADD COLUMN 
  active BOOLEAN;
```

Drop the new `active` column.

```{sql connection=con_ex}
ALTER TABLE 
  link_at 
DROP COLUMN 
  active;
```

Rename `title` column to `link_title`.

```{sql connection=con_ex}
ALTER TABLE 
  link_at 
RENAME 
  title TO link_title;
```

Add a new column `target`.

```{sql connection=con_ex}
ALTER TABLE 
  link_at 
ADD COLUMN 
  target VARCHAR(10);
```

Set `_blank` as the default value for the `target` column.

```{sql connection=con_ex}
ALTER TABLE 
  link_at 
ALTER COLUMN 
  target SET DEFAULT '_blank';
```

```{sql connection=con_ex}
INSERT INTO
  link_at(link_title, url)
VALUES
  ('PostgreSQL Tutorial', 'http://www.postgresqltutorial.com/');
```

```{sql connection=con_ex}
SELECT * FROM link_at;
```

We'll add a `CHECK` condition to the `target` column so it only accepts the following values: `_self`, `_blank`, `_parent`, `_top`.

```{sql connection=con_ex}
ALTER TABLE
  link_at
ADD CHECK
  (target in ('_self', '_blank', '_parent', '_top'));
```

Let's try to violate this `CHECK` constraint.

```{sql connection=con_ex}
INSERT INTO
  link_at(link_title, url, target)
VALUES
  ('PostgreSQL', 'http://www.postgresql.org/', 'whatever');
```

PostgreSQL returns a check constraint error. ^^^

Finally, we'll rename the `link_at` table to `url`.

```{sql connection=con_ex}
ALTER TABLE
  link_at
RENAME TO
  url_at;
```

```{sql connection=con_ex}
SELECT * FROM link_at;
```

```{sql connection=con_ex}
SELECT * FROM url_at;
```

I'm sure there's lots more, but these are nice common `ALTER TABLE` statements that'll come in handy when I start building the unified MADC database.

Disconnect from the _**example**_ database.

```{r}
my_dbDisconnect(con_ex)
```


## RENAME TABLE

To rename an existing table, you use the `ALTER TABLE` statement.

```
ALTER TABLE
  table_name
RENAME TO
  new_table_name;
```

If you want to check the existence of a table before renaming it, use `IF TABLE EXISTS`.

```
ALTER TABLE IF EXISTS
  table_name
RENAME TO
  new_table_name;
```

We'll create new tables to demonstrate this more.

Connect to the _**example**_ database.

```{r}
con_ex <- dbConnect(odbc::odbc(), "PostgreSQL AWS example")
```

```{sql connection=con_ex}
DROP TABLE IF EXISTS vendors CASCADE;
DROP TABLE IF EXISTS groups CASCADE;
DROP TABLE IF EXISTS suppliers CASCADE;
DROP TABLE IF EXISTS supplier_groups CASCADE;
```

```{sql connection=con_ex}
CREATE TABLE IF NOT EXISTS vendors(
  id    SERIAL   PRIMARY KEY,
  name  VARCHAR  NOT NULL
);
```

We'll rename the "vendors" table to "suppliers".

```{sql connection=con_ex}
ALTER TABLE
  vendors
RENAME TO
  suppliers;
```

Suppose each vendor or supplier belongs to a group. To manage this relationship, we need to add a "supplier_groups" table.

```{sql connection=con_ex}
CREATE TABLE IF NOT EXISTS supplier_groups(
  id   SERIAL   PRIMARY KEY,
  name VARCHAR  NOT NULL
);
```

To link these tables up, we need to add a `group_id` column to the "suppliers" table.

```{sql connection=con_ex}
ALTER TABLE
  suppliers
ADD COLUMN
  group_id  INT  NOT NULL;
```

This will be a foreign key that links the `id` column of the "supplier_groups" table.

```{sql connection=con_ex}
ALTER TABLE
  suppliers
ADD FOREIGN KEY
  (group_id) REFERENCES supplier_groups(id);
```

To save time querying complete supplier data, we create a view against the "suppliers" and "supplier_groups" tables. 

```{sql connection=con_ex}
DROP VIEW IF EXISTS supplier_data;
```

```{sql connection=con_ex}
CREATE VIEW
  supplier_data
AS
  SELECT
    s.id,
    s.name,
    g.name AS group
  FROM
    suppliers AS s
  INNER JOIN
    supplier_groups AS g
    ON s.group_id = g.id;
```

When you rename a table to the new one, PostgreSQL will automatically update its dependent objects such as foreign key constraints, views, and indexes.

Let's check the "suppliers" table.

```
ssh -i ~/Box\ Sync/Keys/ubuntu_18_04_postgresql.pem ubuntu@ec2-54-86-62-98.compute-1.amazonaws.com
psql -U postgres
postgres=# \c example
example=# \d suppliers
```

The output shows that the "suppliers" table has a foreign key constraint which references to the "supplier_groups" table:

```
Foreign-key constraints:
    "suppliers_group_id_fkey" FOREIGN KEY (group_id) REFERENCES supplier_groups(id)
```

We now rename the "supplier_groups" table to "groups".

```{sql connection=con_ex}
ALTER TABLE
  supplier_groups
RENAME TO
  groups;
```

And then verify that PostgreSQL updated the table's dependent objects (foreign key constraints, views, indexes).

```
example=# \d suppliers
```

It did:

```
Foreign-key constraints:
    "suppliers_group_id_fkey" FOREIGN KEY (group_id) REFERENCES groups(id)
```

We can also use `psql` to look at the "supplier_data" view.

```
\d+ supplier_data
```

The `SELECT` statement in the `\d+ supplier_data` output appears as:

```
View definition:
 SELECT s.id,
    s.name,
    g.name AS "group"
   FROM suppliers s
     JOIN groups g ON s.group_id = g.id;
```

We can see that the "groups" table was updated here too.

Cool-cool-cool.

Disconnect from the _**example**_ database.

```{r}
my_dbDisconnect(con_ex)
```


## Rename Database

To rename a PostgreSQL database, you use the following steps:

1. Disconnect from the database you want to rename and connect to a different database.
2. Check and terminate all active connections to the database being renamed.
3. Use the `ALTER DATABASE` statement to rename the database.

We'll create a database called _**db**_.

```{r}
con_pg <- dbConnect(odbc::odbc(), "PostgreSQL AWS postgres")
```

```{r}
# if (exists("con_newdb")) { dbDisconnect(con_newdb); rm(con_newdb) }
# if (exists("con_db")) { dbDisconnect(con_db); rm(con_db) }
my_dbDisconnect(con_newdb)
my_dbDisconnect(con_db)
```

```{sql connection=con_pg}
DROP DATABASE IF EXISTS db;
```

```{sql connection=con_pg}
DROP DATABASE IF EXISTS newdb;
```

```{sql connection=con_pg}
CREATE DATABASE db;
```

```{r}
my_dbDisconnect(con_pg)
```

First, connect to a different database. 

```{r}
con_pg <- dbConnect(odbc::odbc(), "PostgreSQL AWS postgres")
```

```{r}
con_db <- dbConnect(odbc::odbc(), "PostgreSQL AWS db")
```

Second, check all the active connections to the _**db**_.

```{sql connection=con_pg}
SELECT
  *
FROM
  pg_stat_activity
WHERE
  datname = 'db';
```

There's an active connection.

```{r}
my_dbDisconnect(con_db)
```

```{sql connection=con_pg}
-- SELECT
--   *
-- FROM
--   pg_stat_activity
-- WHERE
--   datname = 'db';
```

Third, terminal all connections to the database we're looking to rename.

```{sql connection=con_pg}
SELECT
  pg_terminate_backend(9124)
FROM
  pg_stat_activity
WHERE
  datname = 'db';
```

```{sql connection=con_pg}
SELECT
  *
FROM
  pg_stat_activity
WHERE
  datname = 'db';
```

Finally, rename the _**db**_ database to _**newdb**_.

```{sql connection=con_pg}
ALTER DATABASE db RENAME TO newdb;
```

Let's test that it worked.

```{r}
con_newdb <- dbConnect(odbc::odbc(), "PostgreSQL AWS newdb")
```

It worked!

Let's shut it all down.

```{r}
my_dbDisconnect(con_newdb)
my_dbDisconnect(con_db)
my_dbDisconnect(con_pg)
```


## ADD COLUMN

To add a new column to an existing table, you use the `ALTER TABLE` `ADD COLUMN` statement.

Here's the syntax for adding a single column.

```
ALTER TABLE
  table_name
ADD COLUMN
  col_1 {DATATYPE} {CONSTRAINT};
```

Here's for adding multiple columns.

```
ALTER TABLE
  table_name
ADD COLUMN
  col_1 {DATATYPE} {CONSTRAINT},
ADD COLUMN
  col_2 {DATATYPE} {CONSTRAINT},
  ...
ADD COLUMN
  col_n {DATATYPE} {CONSTRAINT};
```

Let's practice.

Connect to the _**example**_ database.

```{r}
con_ex <- dbConnect(odbc::odbc(), "PostgreSQL AWS example")
```

Create a "customers_ac" table.

```{sql connection=con_ex}
DROP TABLE IF EXISTS customers_ac;
```

```{sql connection=con_ex}
CREATE TABLE IF NOT EXISTS customers_ac(
  id             SERIAL   PRIMARY KEY,
  customer_name  VARCHAR  NOT NULL
);
```

Let's add a `phone` column.

```{sql connection=con_ex}
ALTER TABLE
  customers_ac
ADD COLUMN
  phone VARCHAR;
```

Let's add `fax` and `email` columns.

```{sql connection=con_ex}
ALTER TABLE
  customers_ac
ADD COLUMN
  fax    VARCHAR,
ADD COLUMN
  email  VARCHAR;
```

Let's get a description of the "customers_ac" table via psql.

```
psql -U postgres
\c example
\d customers_ac
```

Now we'll try to add a column with a `NOT NULL` constraint to a table that already has records/data.

```{sql connection=con_ex}
INSERT INTO
  customers_ac(customer_name)
VALUES
  ('Apple'),
  ('Samsung'),
  ('Sony');
```

```{sql connection=con_ex}
SELECT * FROM customers_ac;
```

```{sql connection=con_ex}
ALTER TABLE
  customers_ac
ADD COLUMN
  contact_name  VARCHAR  NOT NULL;
```

The above statement throws an error... that `contact_name` contains null values. 

So, here's a workaround.

1. Add the column WITHOUT the `NOT NULL` constraint.
```{sql connection=con_ex}
ALTER TABLE
  customers_ac
ADD COLUMN
  contact_name VARCHAR;
```
2. Update the values of the new column.
```{sql connection=con_ex}
UPDATE customers_ac
SET contact_name = 'John Doe'
WHERE id = 1;

UPDATE customers_ac
SET contact_name = 'Mary Doe'
WHERE id = 2;

UPDATE customers_ac
SET contact_name = 'Lily Bush'
WHERE id = 3;
```
3. Set the new column to `NOT NULL` using `ALTER TABLE`.
```{sql connection=con_ex}
ALTER TABLE
  customers_ac
ALTER COLUMN
  contact_name SET NOT NULL;
```

```{sql connection=con_ex}
SELECT * FROM customers_ac;
```

Another way to solve this problem is to...

1. Set a default value in the new column.
```{sql connection=con_ex}
ALTER TABLE
  customers_ac
ADD COLUMN
  backup_contact  VARCHAR  NOT NULL DEFAULT 'foo';
```

```{sql connection=con_ex}
SELECT * FROM customers_ac;
```

2. Update the values in the new column.
```{sql connection=con_ex}
UPDATE customers_ac
SET backup_contact = 'Suzy Queue'
WHERE id = 1;

UPDATE customers_ac
SET backup_contact = 'James Dean'
WHERE id = 2;

UPDATE customers_ac
SET backup_contact = 'Marilyn Manson'
WHERE id = 3;
```

```{sql connection=con_ex}
SELECT * FROM customers_ac;
```

3. Drop the the default value.
```{sql connection=con_ex}
ALTER TABLE
  customers_ac
ALTER COLUMN
  backup_contact DROP DEFAULT;
```

```{sql connection=con_ex}
--ALTER TABLE
--  customers_ac
--ALTER COLUMN
--  backup_contact SET DEFAULT 'foo';
```

Disconnect from the _**example**_ database.

```{r}
my_dbDisconnect(con_ex)
```


## DROP COLUMN

To drop a column of a table, use a `DROP COLUMN` clause in an `ALTER TABLE` statement.

Here's the syntax.

```
ALTER TABLE
  table_name
DROP COLUMN
  column_name;
```

When you remove a column from a table, PostgreSQL will automatically remove all of its indexes and constraints involving the column. 

If other db objects (like views, triggers, stored procedures, other tables) depend on the column you're trying to drop, PostgreSQL will throw an error. If you want to force the deletion, use `CASCADE` in the `DROP COLUMN` clause.

```
ALTER TABLE
  table_name
DROP COLUMN
  column_name CASCADE;
```

If you try to remove a non-existent column, PostgreSQL will throw an error. To avoid this, use `IF EXISTS`.

```
ALTER TABLE
  table_name
DROP COLUMN IF EXISTS
  column_name;
```

Here's the syntax to drop multiple columns.

```
ALTER TABLE
  table_name
DROP COLUMN col_1,
DROP COLUMN col_2,
...
DROP COLUMN col_n;
```

We'll create three tables for `DROP COLUMN` examples.

Connect to the _**example**_ database.

```{r}
con_ex <- dbConnect(odbc::odbc(), "PostgreSQL AWS example")
```

```{sql connection=con_ex}
DROP TABLE IF EXISTS books_dc;

DROP TABLE IF EXISTS categories_dc;

DROP TABLE IF EXISTS publishers_dc;
```

```{sql connection=con_ex}
CREATE TABLE IF NOT EXISTS publishers_dc(
  publisher_id  SERIAL   PRIMARY KEY,
  name          VARCHAR  NOT NULL
);

CREATE TABLE IF NOT EXISTS categories_dc(
  category_id  SERIAL   PRIMARY KEY,
  name         VARCHAR  NOT NULL
);

CREATE TABLE IF NOT EXISTS books_dc(
  book_id         SERIAL   PRIMARY KEY,
  title           VARCHAR  NOT NULL,
  isbn            VARCHAR  NOT NULL,
  published_date  DATE     NOT NULL,
  description     VARCHAR,
  category_id     INT      NOT NULL,
  publisher_id    INT      NOT NULL,
  FOREIGN KEY (category_id)  REFERENCES categories_dc(category_id),
  FOREIGN KEY (publisher_id) REFERENCES publishers_dc(publisher_id)
);
```

We'll create a view from the "books_dc" and "publishers_dc" tables.

```{sql connection=con_ex}
DROP VIEW IF EXISTS book_info;
```

```{sql connection=con_ex}
CREATE VIEW
  book_info
AS 
SELECT
  b.book_id,
  b.title,
  b.isbn,
  b.published_date,
  p.name
FROM
  books_dc AS b
INNER JOIN
  publishers_dc AS p
  ON b.publisher_id = p.publisher_id;
```

```
ssh -i ~/Box\ Sync/Keys/ubuntu_18_04_postgresql.pem ubuntu@ec2-52-203-155-108.compute-1.amazonaws.com
psql -U postgres
\c example
\d+ book_info
```

Suppose you want to remove the `category_id` column of the "books_dc" table.

```{sql connection=con_ex}
ALTER TABLE
  books_dc
DROP COLUMN
  category_id;
```

Look at the "books_dc" table.

```
ssh -i ~/Box\ Sync/Keys/ubuntu_18_04_postgresql.pem ubuntu@ec2-52-203-155-108.compute-1.amazonaws.com
psql -U postgres
\c example
\d books_dc
```

The column `category_id` and the related foreign key constraint (i.e., `FOREIGN KEY (category_id) REFERENCES categories_dc(category_id)` from above) were removed from "books_dc".

Let's try to remove the `publisher_id` column from "books_dc".

```{sql connection=con_ex}
ALTER TABLE
  books_dc
DROP COLUMN
  publisher_id;
```

Running the above in pgAmin 4 gives a more detailed error:

```
ERROR: cannot drop table books_dc column publisher_id because other objects depend on it DETAIL: view book_info depends on table books_dc column publisher_id HINT: Use DROP ... CASCADE to drop the dependent objects too. SQL state: 2BP01
```

With the more detailed error message, we see that the view "book_info" depends on the `publisher_id` field in the "books_dc" table. To force the column drop, use `CASCADE` (as the error message informs).

```{sql connection=con_ex}
-- We'll execute this in pgAdmin 4 for more detailed return message
ALTER TABLE
  books_dc
DROP COLUMN
  publisher_id CASCADE;
```

pgAdmin 4 returned this message upon executing the above (commented out) code:

```
NOTICE: drop cascades to view book_info 
ALTER TABLE 
Query returned successfully in 107 msec.
```

With the column drop cascading to the view "book_info", "book_info" is destroyed. Executing `\d book_info` returns `Did not find any relation named "book_info".`. So long, short-lived view.

Now we'll remove multiple columns from "books_dc", `isbn` and `description`.

```{sql connection=con_ex}
ALTER TABLE books_dc
DROP COLUMN isbn,
DROP COLUMN description;
```

That's all! Let's disconnect from the _**example**_ database.

```{r}
# if (exists("con_ex")) { dbDisconnect(con_ex); rm(con_ex) }
my_dbDisconnect(con_ex)
```


## Change Column Type

To change the data type of a column, you use the `ALTER TABLE` statement.

Here's the syntax.

```
ALTER TABLE
  table_name
ALTER COLUMN
  col_1 [SET DATA] TYPE {new_data_type};
```

Here's the syntax for re-typing multiple columns.

```
ALTER TABLE table_name
ALTER COLUMN col_1 [SET DATA] TYPE {new_data_type},
ALTER COLUMN col_2 [SET DATA] TYPE {new_data_type},
...
ALTER COLUMN col_n [SET DATA] TYPE {new_data_type};
```

PostgreSQL allows you to re-type a column _**and**_ update the values with `USING`.

```
ALTER TABLE
  table_name
ALTER COLUMN
  col_1 TYPE {new_data_type} USING {expression};
```

We'll create a new table called "assets".

Connect to the _**example**_ database.

```{r}
con_ex <- dbConnect(odbc::odbc(), "PostgreSQL AWS example")
```

```{sql connection=con_ex}
DROP TABLE IF EXISTS assets;
```

```{sql connection=con_ex}
CREATE TABLE IF NOT EXISTS assets(
  id             SERIAL   PRIMARY KEY,
  name           TEXT     NOT NULL,
  asset_no       VARCHAR  NOT NULL,
  description    TEXT,
  location       TEXT,
  acquired_date  DATE     NOT NULL
);
```

```{sql connection=con_ex}
INSERT INTO 
  assets(name, asset_no, location, acquired_date)
VALUES
  ('Server', '10001', 'Server room', '2017-01-01'),
  ('UPS', '10002', 'Server room', '2017-02-01');
```

```{sql connection=con_ex}
SELECT * FROM assets;
```

Let's change the `name` field to `VARCHAR`.

```{sql connection=con_ex}
ALTER TABLE assets
ALTER COLUMN name SET DATA TYPE VARCHAR;
```

Let's also change `description` and `location` to `VARCHAR`.

```{sql connection=con_ex}
ALTER TABLE assets
ALTER COLUMN description SET DATA TYPE VARCHAR,
ALTER COLUMN location    SET DATA TYPE VARCHAR;
```

Let's check it out with `psql`.

```
ssh -i ~/Box\ Sync/Keys/ubuntu_18_04_postgresql.pem ubuntu@ec2-52-203-155-108.compute-1.amazonaws.com
psql -U postgres
\c example
\d assets
```

Looks good!

Let's change the `asset_no` field to integer.

```{sql connection=con_ex}
ALTER TABLE assets
ALTER COLUMN asset_no SET DATA TYPE INT;
```

pgAdmin gives the following (much more helpful) error:

```
ERROR: column "asset_no" cannot be cast automatically to type integer 
HINT: You might need to specify "USING asset_no::integer". 
SQL state: 42804
```

Let's do what PostgreSQL recommends.

```{sql connection=con_ex}
ALTER TABLE assets
ALTER COLUMN asset_no SET DATA TYPE INT using asset_no::integer;
```

```{sql connection=con_ex}
SELECT * FROM assets;
```

We can see here that `asset_no` is now integer type, but I'll check in `psql` again.

```
\d assets
```

Yep, it worked!

Disconnect from the _**example**_ database.

```{r}
my_dbDisconnect(con_ex)
```


## RENAME COLUMN

To rename a column of a table, you use the `ALTER TABLE` statement with `RENAME COLUMN` clause.

Here's the syntax.

```
ALTER TABLE
  table_name
RENAME COLUMN
  column_name TO new_column_name;
```

You can omit the keyword `COLUMN`.

```
ALTER TABLE
  table_name
RENAME
  column_name TO new_column_name;
```

If you try to rename a column that doesn't exist, PostgreSQL will throw an error. To avoid this error, you can use `IF EXISTS`.

```
ALTER TABLE
  table_name
RENAME COLUMN IF EXISTS
  column_name TO new_column_name;
```

Renaming multiple columns in one statment isn't possible with PostgreSQL.

If you rename a column that has dependent objects such as views, foreign key constraints, triggers, or stored procedures, PostgreSQL will update all the dependent objects.

We'll create two new tables, "customers_rc" and "customer_groups_rc", to work through examples.

Connect to the _**example**_ database.

```{r}
con_ex <- dbConnect(odbc::odbc(), "PostgreSQL AWS example")
```

```{sql connection=con_ex}
DROP TABLE IF EXISTS customers_rc;
DROP TABLE IF EXISTS customer_groups_rc;
```

```{sql connection=con_ex}
CREATE TABLE IF NOT EXISTS customer_groups_rc(
  id    SERIAL   PRIMARY KEY,
  name  VARCHAR  NOT NULL
);

CREATE TABLE IF NOT EXISTS customers_rc(
  id        SERIAL   PRIMARY KEY,
  name      VARCHAR  NOT NULL,
  phone     VARCHAR  NOT NULL,
  email     VARCHAR,
  group_id  INT,
  FOREIGN KEY (group_id) REFERENCES customer_groups_rc(id)
);
```

Let's also create a new view "customer_data" based on the tables above.

```{sql connection=con_ex}
DROP VIEW IF EXISTS customer_data;
```

```{sql connection=con_ex}
CREATE VIEW customer_data AS
SELECT
  c.id,
  c.name,
  g.name AS customer_group
FROM
  customers_rc AS c
INNER JOIN
  customer_groups_rc AS g
  ON c.group_id = g.id;
```

Let's rename `email` in the "customers_rc" table to `contact_email`.

```{sql connection=con_ex}
ALTER TABLE customers_rc
RENAME COLUMN email TO contact_email;
```

Check out the results in `psql`.

```
ssh -i ~/Box\ Sync/Keys/ubuntu_18_04_postgresql.pem ubuntu@ec2-52-203-155-108.compute-1.amazonaws.com
psql -U postgres
\c example
\d customers_rc
```

Now let's try to rename a column that has dependent objects. The `name` column in "customer_groups_rc" has a view ("customer_data") that depends on it.

```{sql connection=con_ex}
ALTER TABLE customer_groups_rc
RENAME COLUMN name TO group_name;
```

We'll use `psql` to make sure the column name chnage cascaded to the dependent view.

```
\d+ customer_data
```

In the definition (`SELECT c.id ...`), we can see that `c.name` has been changed to `c.group_name`.

Now for renaming two more columns in "customers_rc.

```{sql connection=con_ex}
ALTER TABLE customers_rc
RENAME COLUMN name TO customer_name;

ALTER TABLE customers_rc
RENAME COLUMN phone TO contact_phone;
```

Disconnect from the _**example**_ database.

```{r}
my_dbDisconnect(con_ex)
```


## DROP TABLE

To remove existing table from the database, you use the `DROP TABLE` statement.

Here's the syntax.

```
DROP TABLE [IF EXISTS] table_name [CASCADE | RESTRICT];
```

`CASCADE` also deletes/drops any database objects (such as views, foreign key constraints, triggers, or stored procedures) that depend on the table be dropped.

`RESTRICT`, used by default, refuses to drop the table if any objects depend on it.

Only a superuser, schema owner, and table owner have sufficient privilege to remove the table.

If you try to drop a table that doesn't exist, PostgreSQL throws an error. To avoid this, you can use `IF EXISTS`.

```
DROP TABLE IF EXISTS table_name;
```

We'll create a couple new tables to demonstrate `DROP TABLE`, "author_dt" and "page_dt".

Connect to the _**example**_ database.

```{r}
con_ex <- dbConnect(odbc::odbc(), "PostgreSQL AWS example")
```

```{sql connection=con_ex}
DROP TABLE IF EXISTS page_dt;
DROP TABLE IF EXISTS author_dt;
```

```{sql connection=con_ex}
CREATE TABLE IF NOT EXISTS author_dt(
  author_id  INT          NOT NULL PRIMARY KEY,
  firstname  VARCHAR(50),
  lastname   VARCHAR(50)
);

CREATE TABLE IF NOT EXISTS page_dt(
  page_id    SERIAL        PRIMARY KEY,
  title      VARCHAR(255)  NOT NULL,
  CONTENT    TEXT,
  author_id  INT           NOT NULL,
  FOREIGN KEY (author_id) REFERENCES author_dt(author_id)
);
```

Look at the details of these tables in `psql`.

```
ssh -i ~/Box\ Sync/Keys/ubuntu_18_04_postgresql.pem ubuntu@ec2-52-203-155-108.compute-1.amazonaws.com
psql -U postgres
\c example
\d author_dt
\d page_dt
```

Try to drop the "author_dt" table.

```{sql connection=con_ex}
DROP TABLE IF EXISTS author_dt;
```

We can't drop the "author_dt" table because there's a foreign key constraint in the "page_dt" table (i.e., the `author_dt` column) that depends on it.

So, use the `CASCADE` keyword to drop the "author_dt" table and its dependents.

```{sql connection=con_ex}
DROP TABLE IF EXISTS author_dt CASCADE;
```

Now checkout the "page_dt" table using `psql`.

```
\d page_dt
```

The foreign key constraint is gone.

Disconnect from the _**example**_ database.

```{r}
my_dbDisconnect(con_ex)
```


## TEMPORARY TABLE

## TRUNCATE TABLE



```{r echo=FALSE}
###@    #==--  :  --==#    @##==---==##@##==---==##@    #==--  :  --==#    @###
#==##@    #==-- --==#    @##==---==##@   @##==---==##@    #==-- --==#    @##==#
#--==##@    #==-==#    @##==---==##@   #   @##==---==##@    #==-==#    @##==--#
#=---==##@    #=#    @##==---==##@    #=#    @##==---==##@    #=#    @##==---=#
##==---==##@   #   @##==---==##@    #==-==#    @##==---==##@   #   @##==---==##
#@##==---==##@   @##==---==##@    #==-- --==#    @##==---==##@   @##==---==##@#
#  @##==---==##@##==---==##@    EXTRA  :  SPACE    @##==---==##@##==---==##@  #
#@##==---==##@   @##==---==##@    #==-- --==#    @##==---==##@   @##==---==##@#
##==---==##@   #   @##==---==##@    #==-==#    @##==---==##@   #   @##==---==##
#=---==##@    #=#    @##==---==##@    #=#    @##==---==##@    #=#    @##==---=#
#--==##@    #==-==#    @##==---==##@   #   @##==---==##@    #==-==#    @##==--#
#==##@    #==-- --==#    @##==---==##@   @##==---==##@    #==-- --==#    @##==#
###@    #==--  :  --==#    @##==---==##@##==---==##@    #==--  :  --==#    @###
#==##@    #==-- --==#    @##==---==##@   @##==---==##@    #==-- --==#    @##==#
#--==##@    #==-==#    @##==---==##@   #   @##==---==##@    #==-==#    @##==--#
#=---==##@    #=#    @##==---==##@    #=#    @##==---==##@    #=#    @##==---=#
##==---==##@   #   @##==---==##@    #==-==#    @##==---==##@   #   @##==---==##
#@##==---==##@   @##==---==##@    #==-- --==#    @##==---==##@   @##==---==##@#
#  @##==---==##@##==---==##@    EXTRA  :  SPACE    @##==---==##@##==---==##@  #
#@##==---==##@   @##==---==##@    #==-- --==#    @##==---==##@   @##==---==##@#
##==---==##@   #   @##==---==##@    #==-==#    @##==---==##@   #   @##==---==##
#=---==##@    #=#    @##==---==##@    #=#    @##==---==##@    #=#    @##==---=#
#--==##@    #==-==#    @##==---==##@   #   @##==---==##@    #==-==#    @##==--#
#==##@    #==-- --==#    @##==---==##@   @##==---==##@    #==-- --==#    @##==#
###@    #==--  :  --==#    @##==---==##@##==---==##@    #==--  :  --==#    @###
```
